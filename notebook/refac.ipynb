{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c185623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import kagglehub\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import make_scorer, fbeta_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c03caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "POPULARITY_THRESHOLD = 85\n",
    "SEED = 42\n",
    "BETA = 1.5\n",
    "\n",
    "RECALL_THRESHOLD = 0.7\n",
    "PRECISION_THRESHOLD = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e23eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "data_path = kagglehub.dataset_download(\"amitanshjoshi/spotify-1million-tracks\")\n",
    "data = pd.read_csv(f\"{data_path}/spotify_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d78f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a152dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['artist_song_count'] = data.groupby('artist_name')['track_id'].transform('count')\n",
    "data['year'] = data['year'].astype(int)\n",
    "yearly_thresholds = data.groupby('year')['popularity'].quantile(POPULARITY_THRESHOLD / 100).to_dict()\n",
    "data['verdict'] = data.apply(lambda row: 1 if row['popularity'] >= yearly_thresholds[row['year']] else 0, axis=1)\n",
    "# calculate the quantiles for duration_ms\n",
    "Q1 = data['duration_ms'].quantile(0.25)\n",
    "Q4 = data['duration_ms'].quantile(0.95)\n",
    "# add feature normal vs long duration\n",
    "data['long_duration'] = data['duration_ms'].apply(lambda x: 1 if x > Q4 else 0)\n",
    "# add feature normal vs short duration\n",
    "data['short_duration'] = data['duration_ms'].apply(lambda x: 1 if x < Q1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41a8e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Unnamed: 0', 'artist_name', 'track_name', 'track_id', 'popularity', 'year', 'duration_ms']\n",
    "data.drop(columns=drop_cols, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'verdict'\n",
    "X = data.drop(columns=[TARGET], errors='ignore')\n",
    "y = data[TARGET]\n",
    "\n",
    "categorical_features = [col for col in ['genre'] if col in X.columns]\n",
    "numerical_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "FEATURES = numerical_features + categorical_features\n",
    "features_target = data[FEATURES + [TARGET]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3502ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(features_target, test_size=0.2, random_state=SEED, stratify=features_target[TARGET])\n",
    "train_input = train_data[FEATURES]\n",
    "train_output = train_data[TARGET]\n",
    "test_input = test_data[FEATURES]\n",
    "test_output = test_data[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"encoder\", OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"numerical\", numerical_transformer, numerical_features),\n",
    "    (\"categorical\", categorical_transformer, categorical_features),\n",
    "])\n",
    "\n",
    "def build_pipeline(estimator):\n",
    "    return Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"estimator\", estimator),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a8723",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1decf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"spotify_popularity_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58176fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mlflow(y_true, y_pred, run_name=\"model\"):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    # Log core metrics\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall) \n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    mlflow.log_metric(\"true_negatives\", tn)\n",
    "    mlflow.log_metric(\"false_positives\", fp)\n",
    "    mlflow.log_metric(\"false_negatives\", fn) \n",
    "    mlflow.log_metric(\"true_positives\", tp)\n",
    "    \n",
    "    # Rates\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    mlflow.log_metric(\"false_positive_rate\", fpr)\n",
    "    mlflow.log_metric(\"false_negative_rate\", fnr)\n",
    "    \n",
    "    print(f\"\\n{run_name} Results:\")\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5813dd32",
   "metadata": {},
   "source": [
    "# III. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc0eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=SEED,\n",
    "                                class_weight='balanced',\n",
    "                                max_depth=5)\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=SEED,\n",
    "                                  class_weight='balanced',\n",
    "                                  n_estimators=100,\n",
    "                                  max_depth=5,\n",
    "                                  max_features='sqrt',\n",
    "                                  min_samples_split=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eb5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train decision tree \n",
    "print(\"Training Decision Tree\")\n",
    "dt_pipeline = build_pipeline(dt_model)\n",
    "dt_pipeline.fit(train_input, train_output)\n",
    "dt_predictions = dt_pipeline.predict(test_input)\n",
    "\n",
    "with mlflow.start_run(run_name=\"decision_tree\"):\n",
    "    mlflow.log_params(dt_model.get_params())\n",
    "    evaluate_mlflow(test_output, dt_predictions, run_name=\"Decision Tree\")\n",
    "    mlflow.sklearn.log_model(dt_pipeline, \"decision_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b9843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"Training Random Forest\")\n",
    "rf_pipeline = build_pipeline(rf_model)\n",
    "rf_pipeline.fit(train_input, train_output)\n",
    "rf_predictions = rf_pipeline.predict(test_input)\n",
    "\n",
    "with mlflow.start_run(run_name=\"random_forest\"):\n",
    "    mlflow.log_params(rf_model.get_params())\n",
    "    evaluate_mlflow(test_output, rf_predictions, run_name=\"Random Forest\")\n",
    "    mlflow.sklearn.log_model(rf_pipeline, \"random_forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788cfcf5",
   "metadata": {},
   "source": [
    "## SearchGridCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78841cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(random_state=SEED, \n",
    "                          objective='binary:logistic',\n",
    "                          n_jobs=-1)\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 600, 800, 1000],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.8],\n",
    "    'scale_pos_weight': [6, 12]\n",
    "}\n",
    "xgb_pipeline = build_pipeline(xgb_model)\n",
    "grid_search = GridSearchCV(xgb_pipeline, \n",
    "                           param_grid, \n",
    "                           scoring='recall_macro', \n",
    "                           cv=3, \n",
    "                           n_jobs=-1, \n",
    "                           verbose=2)\n",
    "grid_search.fit(train_input, train_output)\n",
    "best_estimator = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86165e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictions = best_estimator.predict(test_input)\n",
    "xgb_predictions_proba = best_estimator.predict_proba(test_input)[:, 1]\n",
    "\n",
    "# Log to MLflow\n",
    "with mlflow.start_run(run_name=\"xgboost\") as run:\n",
    "    for param, value in best_params.items():\n",
    "        mlflow.log_param(param, value)\n",
    "    \n",
    "    mlflow.log_metric(\"best_cv_score\", grid_search.best_score_)\n",
    "    mlflow.log_metric(\"cv_score_std\", grid_search.cv_results_['std_test_score'][grid_search.best_index_])\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    evaluate_mlflow(test_output, xgb_predictions, run_name=\"XGBoost\")\n",
    "    \n",
    "    # Log the best model - FIXED: Ensure model is properly logged\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=best_estimator,\n",
    "        artifact_path=\"model\",  # Changed from \"xgboost_tuned\" to \"model\" for standard practice\n",
    "        registered_model_name=\"spotify_popularity_predictor2\"  # Register the model\n",
    "    )\n",
    "    \n",
    "    # Also log additional information\n",
    "    mlflow.set_tag(\"model_type\", \"XGBoost\")\n",
    "    mlflow.set_tag(\"pipeline\", \"True\")\n",
    "    mlflow.set_tag(\"feature_count\", str(test_input.shape[1]))\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    print(f\"Run ID: {run_id}\")\n",
    "    print(f\"Model logged successfully! Artifact path: model\")\n",
    "    \n",
    "    # Verify the model can be loaded back\n",
    "    try:\n",
    "        # Test loading the model immediately\n",
    "        loaded_model = mlflow.sklearn.load_model(f\"runs:/{run_id}/model\")\n",
    "        test_pred = loaded_model.predict(test_input[:1])\n",
    "        print(f\"✓ Model verification: Successfully loaded and made prediction: {test_pred[0]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Model verification failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOps-Spotify (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
